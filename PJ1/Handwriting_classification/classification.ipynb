{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The code aims to classify the handwritten words, which is classification in this case.'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "category=12\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    x=[]\n",
    "    y=[]\n",
    "    x_test=[]\n",
    "    y_test=[]\n",
    "    \n",
    "    for i in range(category):\n",
    "        root = f'../train/{i+1}'\n",
    "        filenames = os.listdir(root)\n",
    "        np.random.shuffle(filenames)  \n",
    "        test_num = 0\n",
    "        for filename in filenames:\n",
    "            img_root = os.path.join(root, filename)\n",
    "            image = Image.open(img_root)\n",
    "            if test_num < (int)(0.2*len(filenames)):\n",
    "                x_test.append(np.array(image).flatten())\n",
    "                y_test.append([1 if j == i else 0 for j in range(12)])\n",
    "                test_num += 1\n",
    "            else:\n",
    "                x.append(np.array(image).flatten())\n",
    "                y.append([1 if j == i else 0 for j in range(12)])\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return x, y, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MLP(input, output):\n",
    "    W1 = np.random.randn(input, output)/np.sqrt(input*output)\n",
    "    b1 = np.random.randn(output)/np.sqrt(output)\n",
    "    return W1, b1\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, input, output,activation=\"\"):\n",
    "        self.W1, self.b1= make_MLP(input, output)\n",
    "        self.activation = activation\n",
    "    def forward(self,x):\n",
    "        self.x=x\n",
    "        self.z1 = np.dot(x, self.W1) + self.b1\n",
    "        self.a1= self.z1\n",
    "        if self.activation==\"sigmoid\":\n",
    "            self.a1 = sigmoid(self.z1)\n",
    "        return self.a1\n",
    "    def backward(self,lossdx,learning_rate):\n",
    "        # x y is the batch data\n",
    "        dW1 = np.zeros_like(self.W1)  # (input, hidden_layer)\n",
    "        db1 = np.zeros_like(self.b1)  # (hidden_layer)\n",
    "\n",
    "        z1 = self.z1\n",
    "        a1 = self.a1 \n",
    "        \n",
    "        if self.activation==\"sigmoid\":\n",
    "            lossdx =  a1 * (1-a1) *lossdx\n",
    "        print(\"the shape of lossdx\",lossdx.shape)\n",
    "        print(\"the shape of x\",self.x.shape)\n",
    "        print(\"the shape of W1\",self.W1.shape)\n",
    "        print(\"the shape of dW1\",dW1.shape)\n",
    "        print(\"the shape of db1\",db1.shape)\n",
    "        print(\"the shape of z1\",z1.shape)\n",
    "        print(\"the shape of a1\",a1.shape)\n",
    "        db1 += lossdx\n",
    "        try:\n",
    "            dW1 += np.dot(self.x,lossdx.T)\n",
    "        except:\n",
    "            self.x=self.x.reshape(-1,1)\n",
    "            lossdx=lossdx.reshape(-1,1)\n",
    "            dW1 += np.dot(self.x,lossdx.T)\n",
    "        \n",
    "        lossdx = np.dot(self.W1,lossdx)\n",
    "        self.W1 -= learning_rate*dW1/len(self.x) # /the batch size\n",
    "        self.b1 -= learning_rate*db1/len(self.x)\n",
    "        print(\"the shape of lossdx\",lossdx.shape)\n",
    "        print(\"************************\")\n",
    "        return lossdx.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68526785 0.19487044 0.69000968 0.21042554 0.00480183]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([1,2,3,4,5,6,7])\n",
    "net=Layer(7,5,\"sigmoid\")\n",
    "print(net.forward(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of lossdx (5,)\n",
      "the shape of x (7,)\n",
      "the shape of W1 (7, 5)\n",
      "the shape of dW1 (7, 5)\n",
      "the shape of db1 (5,)\n",
      "the shape of z1 (5,)\n",
      "the shape of a1 (5,)\n",
      "the shape of lossdx (7, 1)\n",
      "************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.09262614,  0.10439036, -0.16193458,  0.01597333, -0.08037689,\n",
       "       -0.0568763 ,  0.09800388])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.backward(np.array([1,1,1,1,1]),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self):\n",
    "        self.layers=[]\n",
    "    def add_layer(self,layer):\n",
    "        self.layers.append(layer)\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x=layer.forward(x)\n",
    "        self.output=x\n",
    "        x=softmax(x)\n",
    "        return x\n",
    "    def backward(self,y,learning_rate):\n",
    "        # we first calculate the lossdx of the last layer\n",
    "        lossdx = y-self.output\n",
    "        for layer in self.layers[::-1]:\n",
    "            lossdx=layer.backward(lossdx,learning_rate)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2441439 , 0.24902651, 0.5068296 ])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp=MLP()\n",
    "mlp.add_layer(Layer(5,9,\"sigmoid\"))\n",
    "mlp.add_layer(Layer(9,3))\n",
    "mlp.forward(np.array([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of lossdx (3,)\n",
      "the shape of x (9,)\n",
      "the shape of W1 (9, 3)\n",
      "the shape of dW1 (9, 3)\n",
      "the shape of db1 (3,)\n",
      "the shape of z1 (3,)\n",
      "the shape of a1 (3,)\n",
      "the shape of lossdx (9, 1)\n",
      "************************\n",
      "the shape of lossdx (9,)\n",
      "the shape of x (5,)\n",
      "the shape of W1 (5, 9)\n",
      "the shape of dW1 (5, 9)\n",
      "the shape of db1 (9,)\n",
      "the shape of z1 (9,)\n",
      "the shape of a1 (9,)\n",
      "the shape of lossdx (5, 1)\n",
      "************************\n"
     ]
    }
   ],
   "source": [
    "mlp.backward(np.array([1,0,0]),0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
